{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.agents import create_pandas_dataframe_agent\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv \n",
    "import json\n",
    "import os\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_key = os.getenv(\"YOUR OPEN AI KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_tool(filename : str):\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "    return create_pandas_dataframe_agent(OpenAI(temperature=0), df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_agent(agent, query):\n",
    "    \"\"\"\n",
    "    Query an agent and return the response as a string.\n",
    "\n",
    "    Args:\n",
    "        agent: The agent to query.\n",
    "        query: The query to ask the agent.\n",
    "\n",
    "    Returns:\n",
    "        The response from the agent as a string.\n",
    "    \"\"\"\n",
    "    # Prepare the prompt with query guidelines and formatting\n",
    "    prompt = (\n",
    "        \"\"\"\n",
    "        Let's decode the way to respond to the queries. The responses depend on the type of information requested in the query. \n",
    "\n",
    "        1. If the query requires a table, format your answer like this:\n",
    "           {\"table\": {\"columns\": [\"column1\", \"column2\", ...], \"data\": [[value1, value2, ...], [value1, value2, ...], ...]}}\n",
    "\n",
    "        2. For a bar chart, respond like this:\n",
    "           {\"bar\": {\"columns\": [\"A\", \"B\", \"C\", ...], \"data\": [25, 24, 10, ...]}}\n",
    "\n",
    "        3. If a line chart is more appropriate, your reply should look like this:\n",
    "           {\"line\": {\"columns\": [\"A\", \"B\", \"C\", ...], \"data\": [25, 24, 10, ...]}}\n",
    "\n",
    "        Note: We only accommodate two types of charts: \"bar\" and \"line\".\n",
    "\n",
    "        4. For a plain question that doesn't need a chart or table, your response should be:\n",
    "           {\"answer\": \"Your answer goes here\"}\n",
    "\n",
    "        For example:\n",
    "           {\"answer\": \"The Product with the highest Orders is '15143Exfo'\"}\n",
    "\n",
    "        5. If the answer is not known or available, respond with:\n",
    "           {\"answer\": \"I do not know.\"}\n",
    "\n",
    "        Return all output as a string. Remember to encase all strings in the \"columns\" list and data list in double quotes. \n",
    "        For example: {\"columns\": [\"Products\", \"Orders\"], \"data\": [[\"51993Masc\", 191], [\"49631Foun\", 152]]}\n",
    "\n",
    "        Now, let's tackle the query step by step. Here's the query for you to work on: \n",
    "        \"\"\"\n",
    "        + query\n",
    "    )\n",
    "\n",
    "    # Run the prompt through the agent and capture the response.\n",
    "    response = agent.run(prompt)\n",
    "\n",
    "    # Return the response converted to a string.\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_response(response: str) -> dict:\n",
    "    \"\"\"This function converts the string response from the model to a dictionary object.\n",
    "\n",
    "    Args:\n",
    "        response (str): response from the model\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary with response data\n",
    "    \"\"\"\n",
    "    return json.loads(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_answer(response_dict: dict):\n",
    "    \"\"\"\n",
    "    Write a response from an agent to a Streamlit app.\n",
    "\n",
    "    Args:\n",
    "        response_dict: The response from the agent.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the response is an answer.\n",
    "    if \"answer\" in response_dict:\n",
    "        st.write(response_dict[\"answer\"])\n",
    "\n",
    "    # Check if the response is a bar chart.\n",
    "    # Check if the response is a bar chart.\n",
    "    if \"bar\" in response_dict:\n",
    "        data = response_dict[\"bar\"]\n",
    "        try:\n",
    "            df_data = {\n",
    "                    col: [x[i] if isinstance(x, list) else x for x in data['data']]\n",
    "                    for i, col in enumerate(data['columns'])\n",
    "                }       \n",
    "            df = pd.DataFrame(df_data)\n",
    "            df.set_index(\"Products\", inplace=True)\n",
    "            st.bar_chart(df)\n",
    "        except ValueError:\n",
    "            print(f\"Couldn't create DataFrame from data: {data}\")\n",
    "\n",
    "# Check if the response is a line chart.\n",
    "    if \"line\" in response_dict:\n",
    "        data = response_dict[\"line\"]\n",
    "        try:\n",
    "            df_data = {col: [x[i] for x in data['data']] for i, col in enumerate(data['columns'])}\n",
    "            df = pd.DataFrame(df_data)\n",
    "            df.set_index(\"Products\", inplace=True)\n",
    "            st.line_chart(df)\n",
    "        except ValueError:\n",
    "            print(f\"Couldn't create DataFrame from data: {data}\")\n",
    "\n",
    "\n",
    "    # Check if the response is a table.\n",
    "    if \"table\" in response_dict:\n",
    "        data = response_dict[\"table\"]\n",
    "        df = pd.DataFrame(data[\"data\"], columns=data[\"columns\"])\n",
    "        st.table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 17:33:37.930 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/gesskay/anaconda3/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "st.set_page_config(page_title=\"üë®‚Äçüíª Talk with your CSV\")\n",
    "st.title(\"üë®‚Äçüíª Talk with your CSV\")\n",
    "\n",
    "st.write(\"Please upload your CSV file below.\")\n",
    "\n",
    "data = st.file_uploader(\"Upload a CSV\" , type=\"csv\")\n",
    "\n",
    "query = st.text_area(\"Send a Message\")\n",
    "\n",
    "if st.button(\"Submit Query\", type=\"primary\"):\n",
    "    # Create an agent from the CSV file.\n",
    "    agent = csv_tool(data)\n",
    "\n",
    "    # Query the agent.\n",
    "    response = ask_agent(agent=agent, query=query)\n",
    "\n",
    "    # Decode the response.\n",
    "    decoded_response = decode_response(response)\n",
    "\n",
    "    # Write the response to the Streamlit app.\n",
    "    write_answer(decoded_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c17b1c52172efd66d111ec3ba179bea7bc526d1f51b1a1bcda07db359562aedd"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
